
Anschließend an die Durchführung des Laborexperiments werden innerhalb dieses Kapitels die erzeugten Messdaten betrachtet und die zur Beantwortung der Forschungsfrage aufgestellten Hypothesen ausgewertet.
Es gilt dabei einen möglichen Effekt des trainierten Gegenspielers auf die Robustheit des RL-Modells zu untersuchen.
Dazu werden die Leistungen der Strategien aus den unterschiedlichen Trainingsszenarien im abweichenden Testszenario verglichen.
Die auszuwertenden Leistungsmetriken aggregiert zu ihrer Testepisode sind im Anhang nachzulesen.
Im ersten Vergleich werden die Strategie aus dem Training mit regelbasiertem und mittels RL optimierten Gegenspieler untersucht.
Weiterhin wird ein Vergleich der Testmetriken zwischen dem Training ohne und mit randomisierter Umgebung sowie regelbasiertem Gegenspieler durchgeführt.
Das Ende dieses Kapitels bildet die Beantwortung der Forschungsfrage anhand der ausgewerteten Test- und Forschungshypothesen.

\section{Vergleich der Robustheit der Strategien aus dem Training mit regelbasierten und RL Gegenspieler}

\begin{table}[htb]
    \begin{tabular}{llllll}
    Metrik & Gleichheit P-Wert & Verschlechterung P-Wert & Ungleichheit & Verbesserung \\
    sum reward & 0.48390799726891964 & 0.7588082897727775 & False & False \\
    \begin{tabular}[c]{@{}l@{}}reward mean \\ difference\end{tabular} & 0.007654101554906155 & 0.9962006818665161 & True & False \\
    count of fails & 0.005412977104604817 & 0.0027064885523024086 & True & True
    \end{tabular}
    \caption{Ergebnisse der statistischen Tests aus dem Leistungsvergleich der Modelle aus den Trainingsszenarien 1 und 3}
    \label{tab:my-table}
\end{table}

\subsection{Betrachtung der kumulierten Belohnung}

\textbf{Hypothese 1:}
\textit{Die im Testszenario erzielte kumulierte Belohnung ist unter Verwendung der Policy aus dem Training mit RL basiertem Gegenspieler signifikant und zuverlässig höher als die Policy aus dem Training mit regelbasiertem Gegenspieler.}

\subsection{Betrachtung der Belohnungsstabilität}

\textbf{Hypothese 2:}
\textit{Die Varianz der im Testszenario erzielten kumulierten Belohnung ist unter Verwendung der Policy aus dem Training mit RL basiertem Gegenspieler signifikant und zuverlässig geringer als die Policy aus dem Training mit regelbasiertem Gegenspieler.}

\textbf{Hier am Ende vlt auch die wirkliche Varianz berechnen}

\subsection{Betrachtung der Anzahl der Misserfolge}

\textbf{Hypothese 3:}
\textit{Die im Testszenario erreichte Anzahl von Misserfolgen ist unter Verwendung der Policy aus dem Training mit RL basiertem Gegenspieler signifikant und zuverlässig geringer als die Policy aus dem Training mit regelbasiertem Gegenspieler.}