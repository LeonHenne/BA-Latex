\section{Robustheit und Stabilität von Strategien des verstärkenden Lernens}

Anders als innerhalb von Simulationen, lassen sich in der echten Welt häufig Unsicherheiten, Störeinflüsse und grundlegende Veränderungen der Umgebung wahrnehmen, für welche die Methoden des RL standardmäßig nicht robust genug sind. \footcite[Vgl.][S. 1]{Moos.2022}
Im nachfolgenden Kapitel wird daher genauer dargestellt, was unter der Robustheit von Algorithmen des verstärkenden Lernens verstanden wird, was Kenngrößen sind und in welchem Kontext sich diese messen lassen.

\subsection{Definitionen von Robustheit und Stabilität}

In der aktuellen Forschungsliteratur findet sich nur eine geringe Gemeinsamkeit innerhalb der unterschiedlichen Definitionen von Stabilität und Robustheit. \footcite[Vgl.][S. 5]{Pullum.2022}
Die Definition der Robustheit im Kontext von verstärkendem Lernen wird verschieden interpretiert, wie z.B. als Robustheit gegen Störeinflüsse, Beeinflussung der Belohnung, oder Umgebungsunterschiede. \footcite[Vgl.][S. 2]{Liu.2023}
\cite[]{Pullum.2022} definiert Stabilität und Robustheit im Kontext der Literaturanalyse wie folgt:

\textit{Stabilität ist eine Eigenschaft des lernenden Algorithmus, die sich auf dessen Leistungsvarianz bezieht und bei geringer Varianz auf ein stabiles Modell hinweist.} \footcite[Vgl.][S. 5]{Pullum.2022}

\textit{Robustheit im Kontext von Software, referenziert eine Eigenschaft eines System, welches nicht nur ausschließlich unter normalen, sondern auch unter außergewöhnlichen Bedingungen, die die Annahmen des Entwicklers übersteigen, gut funktioniert.} \footcite[Vgl.][S. 5]{Pullum.2022}

\cite[]{Moos.2022} beschreibt die Robustheit in seiner Literaturanalyse als Fähigkeit mit Variationen und Unsicherheiten in der Umgebung umgehen zu können, wobei Unsicherheiten häufig variierende physische Parameter darstellen. \footcite[Vgl.][S. 1]{Moos.2022}

\subsection{Metriken der Robustheit}

Werden Algorithmen und der Erfolg von Veränderungen dieser Experimente betrachtet, kommt es oftmals dazu, dass nur die Leistung und Stabilität verglichen wird, und so die Belohnung die einzige Kenngröße bildet. \footcite[Vgl.][S. 6]{YanDuan.2016}
Wird diese Metrik im Kontext unterschiedlicher Umgebungen überprüft, kann allerdings so auch die Robustheit von RL Algorithmen betrachtet werden. \footcite[Vgl.][S. 6]{Pinto.2017}
Neben Betrachtung der Belohnung lassen sich auch weitere quantitative sowie qualitative Kenngrößen untersuchen, welche die Robustheit und Stabilität eines Algorithmus innerhalb der Umgebung widerspiegeln. \footcite[Vgl.][S. 15]{Pullum.2022}
In der Literaturanalyse nach \cite[]{Pullum.2022} werden quantitative Metriken zusätzlich nach internen Kenngrößen, welche den Trainingsprozess beschreiben, und externen Kenngrößen, welche die Modellqualität repräsentieren, klassifiziert sowie folgende Tabellen drei und vier zu dessen Metriken angeführt. \footcite[Vgl.][S. 16]{Pullum.2022}

\begin{table}[htb]
    \centering
    \begin{tabular}{cc|c|}
        \hline
        \rowcolor[HTML]{EFEFEF} 
        \multicolumn{1}{|c|}{\cellcolor[HTML]{EFEFEF}\textbf{\begin{tabular}[c]{@{}c@{}}Internal Quantitative\\ Metric\end{tabular}}}                                                         & \textbf{Behavior}                                               & \textbf{Total citations}            \\ \hline
        \multicolumn{1}{|c|}{\begin{tabular}[c]{@{}c@{}}Reward or Score –\\ magnitude, mean/\\ variance, variation in\\ average reward, time to\\ threshold, episode duration\end{tabular}} & \begin{tabular}[c]{@{}c@{}}Stability,\\ Robustness\end{tabular} & 75                                  \\ \hline
        \multicolumn{1}{|c|}{Policy entropy}                                                                                                                                                  & Stability                                                       & 2                                   \\ \hline
        \multicolumn{1}{|c|}{\begin{tabular}[c]{@{}c@{}}Variations in control \\ strategy approximation weights\end{tabular}}                                                              & \begin{tabular}[c]{@{}c@{}}Stability,\\ Robustness\end{tabular} & 2                                   \\ \hline
        \multicolumn{1}{|c|}{Convergence rate}                                                                                                                                                & Stability                                                       & 2                                   \\ \hline
        \multicolumn{1}{|c|}{\begin{tabular}[c]{@{}c@{}}Lyapunov stability criteria calculated\end{tabular}}                                                                                & Stability                                                       & 1                                   \\ \hline
        \multicolumn{1}{|c|}{Policy weight}                                                                                                                                                   & Robustness                                                      & 1                                   \\ \hline
        \multicolumn{1}{|c|}{Regret}                                                                                                                                                          & Robustness                                                      & 1                                   \\ \hline
        \multicolumn{1}{|c|}{\begin{tabular}[c]{@{}c@{}}Wasserstein function\\ bounds calculated\end{tabular}}                                                                                & Robustness                                                      & 1                                   \\ \hline
        \multicolumn{1}{l}{}                                                                                                                                                                  & \multicolumn{1}{l|}{}                                           & \cellcolor[HTML]{EFEFEF}\textbf{85} \\ \cline{3-3} 
    \end{tabular}
    \caption{Interne quantitative Metriken, dessen gemessenes Verhalten und ihre Häufigkeit\footcite[][S.17]{Pullum.2022}}
    \label{tab:quantitive metric}
\end{table}
\footnotetext{Ähnlich enthalten in: \cite[][S.17]{Pullum.2022}}

\begin{table}[htb]
    \centering
    \begin{tabular}{cc|c|}
    \hline
    \rowcolor[HTML]{EFEFEF} 
    \multicolumn{1}{|c|}{\cellcolor[HTML]{EFEFEF}\textbf{\begin{tabular}[c]{@{}c@{}}External Quantitative\\ Metric\end{tabular}}} & \textbf{Behavior} & \textbf{Total citations} \\ \hline
    \multicolumn{1}{|c|}{\begin{tabular}[c]{@{}c@{}}Deviations/variation in other (than\\ precision, accuracy and recall)\\ performance-related metrics\end{tabular}} & \begin{tabular}[c]{@{}c@{}}Stability,\\ Robustness,\\ Resilience\end{tabular} & 39 \\ \hline
    \multicolumn{1}{|c|}{Error and failure rates/success rate} & \begin{tabular}[c]{@{}c@{}}Stability,\\ Robustness\end{tabular} & 28 \\ \hline
    \multicolumn{1}{|c|}{\begin{tabular}[c]{@{}c@{}}Performance of tracking/trajectories\\ estimation error; mean absolute\\ deviation, mean square error, mean\\ absolute percentage error, margins\\ and magnitude of correlation\\ coefficient\end{tabular}} & \begin{tabular}[c]{@{}c@{}}Stability,\\ Robustness\end{tabular} & 23 \\ \hline
    \multicolumn{1}{|c|}{\begin{tabular}[c]{@{}c@{}}Network-related timing/delay, path\\ and link metrics, connectivity,\\ delivery ratio, routing loops, path\\ optimality, visitation distribution,\\ structural Hamming distance, Small\\ base station-serving ratio, sum-rate\\ and 5th percentile rate\end{tabular}} & \begin{tabular}[c]{@{}c@{}}Stability,\\ Robustness\end{tabular} & 15 \\ \hline
    \multicolumn{1}{|c|}{\begin{tabular}[c]{@{}c@{}}Mean/average and variation inaccuracy, \\ precision and recall, area under \\ the receiver operating characteristic \\ (ROC) curve (AUC)\end{tabular}} & \begin{tabular}[c]{@{}c@{}}Stability,\\ Robustness,\\ Resilience\end{tabular} & 12 \\ \hline
    \multicolumn{1}{|c|}{\begin{tabular}[c]{@{}c@{}}Variance of the estimation of loss,\\ regret\end{tabular}} & Robustness & 5 \\ \hline
    \multicolumn{1}{l}{} & \multicolumn{1}{l|}{} & \cellcolor[HTML]{EFEFEF}\textbf{122} \\ \cline{3-3} 
    \end{tabular}
    \caption{Auszug der externen quantitativen Metriken, dessen gemessenes Verhalten und ihre Häufigkeit\footcite[][S.19]{Pullum.2022}}
    \label{tab:qualitive metric}
\end{table}
\footnotetext{Ähnlich enthalten in: \cite[][S.19]{Pullum.2022}}

\subsection{Experimenteller Rahmen zur Messung der Robustheit}

Die Tabellen drei und vier zeigen auf, dass trotz der Existenz weiterer Metriken, die Belohnung, deren Durchschnitt, Varianz und Entwicklung am häufigsten eingesetzt werden, um die Robustheit von RL Algorithmen zu messen.
Dabei werden Experimente unter festgelegten oder optimierten Hyperparametern, in mehreren Simulationsumgebungen  durchgeführt, um aus dem Vergleich derselben Strategie in unterschiedlichen Umfeldern, Rückschlüsse auf die Robustheit zu ziehen. \footcite[Vgl.][S. 5]{Pinto.2017}
Unterschiede in den Umgebungen können bspw. durch fixe Dynamiken wie z.B. Reibwerte während des Trainingsprozesses und unterschiedlicher Reibwerte während der Testphase realisiert werden. \footcite[Vgl.][S. 6]{Pinto.2017}
Ein weiterer Ansatz kann die Sim-to-Sim Verifikation sein, bei der die optimierten Strategien in einer nicht während des Trainings verwendeten Simulationen untersucht werden. \footcite[Vgl.][S. 5]{Molchanov.2019}