% Encoding: UTF-8

% This file was created with Citavi 6.12.0.177

@proceedings{.2014,
 year = {2014},
 title = {2014 IEEE International Conference on Robotics and Automation (ICRA)},
 publisher = {IEEE},
 file = {Reinforcement learning with multi-fidelity simulators:Attachments/Reinforcement learning with multi-fidelity simulators.pdf:application/pdf}
}


@proceedings{.2018,
 year = {2018},
 title = {2018 14th International Wireless Communications {\&} Mobile Computing Conference (IWCMC)},
 publisher = {IEEE}
}


@proceedings{.2019,
 year = {2019},
 title = {2019 International Conference on Robotics and Automation (ICRA)},
 publisher = {IEEE},
 file = {A Data-Efficient Framework for Training and Sim-to-Real:Attachments/A Data-Efficient Framework for Training and Sim-to-Real.pdf:application/pdf}
}


@proceedings{.2020,
 year = {2020},
 title = {2020 IEEE Symposium Series on Computational Intelligence (SSCI)},
 publisher = {IEEE},
 file = {Sim-to-Real Transfer in Deep Reinforcement Learning for:Attachments/Sim-to-Real Transfer in Deep Reinforcement Learning for.pdf:application/pdf}
}


@proceedings{.2021,
 year = {2021},
 title = {Proceedings of the 22nd International Workshop on Mobile Computing Systems and Applications},
 address = {New York, NY, USA},
 publisher = {ACM},
 file = {GrGym:Attachments/GrGym.pdf:application/pdf}
}


@proceedings{.2021b,
 year = {2021},
 title = {International Conference on Practical Applications of Agents and Multi-Agent Systems},
 publisher = {{Springer, Cham}},
 file = {Advances in Practical Applications of Agents Multi-Agent:Attachments/Advances in Practical Applications of Agents Multi-Agent.pdf:application/pdf}
}


@book{.2021c,
 year = {2021},
 title = {Interactive Robust Policy Optimization for Multi-Agent Reinforcement Learning},
 url = {https://openreview.net/forum?id=edjy_h3_umk},
 file = {Interactive Robust Policy Optimization for Multi-Agent R:Attachments/Interactive Robust Policy Optimization for Multi-Agent R.pdf:application/pdf}
}


@book{.2021d,
 year = {2021},
 title = {Advances in Data Science and Information Engineering},
 publisher = {{Springer, Cham}},
 file = {Advances in Data Science and Information Engineering:Attachments/Advances in Data Science and Information Engineering.pdf:application/pdf}
}


@book{.2021e,
 year = {2021},
 title = {Adversarial Swarm Defense with Decentralized Swarms},
 url = {https://digitalassets.lib.berkeley.edu/techreports/ucb/incoming/eecs-2021-81.pdf},
 file = {Adversarial Swarm Defense with Decentralized Swarms:Attachments/Adversarial Swarm Defense with Decentralized Swarms.pdf:application/pdf}
}


@proceedings{.2022,
 year = {2022},
 title = {2022 IEEE/AIAA 41st Digital Avionics Systems Conference (DASC)},
 publisher = {IEEE}
}


@article{.2023,
 year = {2023},
 title = {Sim-to-Lab-to-Real: Safe reinforcement learning with shielding and generalization guarantees},
 url = {https://www.sciencedirect.com/science/article/pii/s0004370222001515},
 pages = {103811},
 volume = {314},
 issn = {0004-3702},
 journal = {Artificial Intelligence},
 doi = {10.1016/j.artint.2022.103811},
 file = {Sim-to-Lab-to-Real Safe reinforcement learning with shie:Attachments/Sim-to-Lab-to-Real Safe reinforcement learning with shie.pdf:application/pdf}
}


@proceedings{.5302021652021,
 year = {5/30/2021 - 6/5/2021},
 title = {2021 IEEE International Conference on Robotics and Automation (ICRA)},
 publisher = {IEEE},
 isbn = {978-1-7281-9077-8}
}


@incollection{Ahmed.,
 author = {Ahmed, Ibrahim and Quinones-Grueiro, Marcos and Biswas, Gautam},
 title = {A high-fidelity simulation test-bed for fault-tolerant octo-rotor control using reinforcement learning},
 pages = {1--10},
 doi = {10.1109/DASC55683.2022.9925862},
 file = {A_high-fidelity_simulation_test-bed_for_fault-tolerant_octo-rotor_control_using_reinforcement_learning:Attachments/A_high-fidelity_simulation_test-bed_for_fault-tolerant_octo-rotor_control_using_reinforcement_learning.pdf:application/pdf}
}


@inproceedings{Ahmed.2022,
 author = {Ahmed, Ibrahim and Quinones-Grueiro, Marcos and Biswas, Gautam},
 title = {A high-fidelity simulation test-bed for fault-tolerant octo-rotor control using reinforcement learning},
 publisher = {IEEE},
 booktitle = {2022 IEEE/AIAA 41st Digital Avionics Systems Conference (DASC)},
 year = {2022},
 doi = {10.1109/dasc55683.2022.9925862}
}


@inproceedings{Alghonaim.5302021652021,
 author = {Alghonaim, Raghad and Johns, Edward},
 title = {Benchmarking Domain Randomisation for Visual Sim-to-Real Transfer},
 pages = {12802--12808},
 publisher = {IEEE},
 isbn = {978-1-7281-9077-8},
 booktitle = {2021 IEEE International Conference on Robotics and Automation (ICRA)},
 year = {5/30/2021 - 6/5/2021},
 doi = {10.1109/ICRA48506.2021.9561134},
 file = {Benchmarking Domain Randomisation for Visual Sim-to-Real:Attachments/Benchmarking Domain Randomisation for Visual Sim-to-Real.pdf:application/pdf}
}


@Inproceedings{Ancuti,
  Title                    = {Enhancing underwater images and videos by fusion},
  Author                   = {Ancuti, C. and Ancuti, C.O. and Haber, T. and Bekaert, P.},
  Booktitle                = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  Year                     = {2012},
  Doi                      = {10.1109/CVPR.2012.6247661},
  Pages                    = {81-88},

  Abstract                 = {This paper describes a novel strategy to enhance underwater videos and images. Built on the fusion principles, our strategy derives the inputs and the weight measures only from the degraded version of the image. In order to overcome the limitations of the underwater medium we define two inputs that represent color corrected and contrast enhanced versions of the original underwater image/frame, but also four weight maps that aim to increase the visibility of the distant objects degraded due to the medium scattering and absorption. Our strategy is a single image approach that does not require specialized hardware or knowledge about the underwater conditions or scene structure. Our fusion framework also supports temporal coherence between adjacent frames by performing an effective edge preserving noise reduction strategy. The enhanced images and videos are characterized by reduced noise level, better exposed-ness of the dark regions, improved global contrast while the finest details and edges are enhanced significantly. In addition, the utility of our enhancing technique is proved for several challenging applications.},
  Bdsk-url-1               = {http://dx.doi.org/10.1109/CVPR.2012.6247661},
  ISSN                     = {1063-6919},
  Keywords                 = {image colour analysis;image denoising;image enhancement;image fusion;light absorption;light scattering;video signal processing;adjacent frames;color corrected version;contrast enhanced version;distant objects degradation;edge preserving noise reduction strategy;enhancing technique;fusion framework;fusion principles;global contrast;image fusion;medium absorption;medium scattering;reduced noise level;single image approach;temporal coherence;underwater conditions;underwater image enhancement;underwater scene structure;underwater videos enhancement;weight maps;Image color analysis;Image edge detection;Image restoration;Laplace equations;Lighting;Noise;Videos}
}


@article{Bernstein2014,
  abstract = {This issue's "Cloud Tidbit" focuses on container technology and how it's emerging as an important part of the cloud computing infrastructure. It looks at Docker, an open source project that automates the faster deployment of Linux applications, and Kubernetes, an open source cluster manager for Docker containers.},
  author = {Bernstein, David},
  doi = {10.1109/MCC.2014.51},
  issn = {23256095},
  journal = {IEEE Cloud Computing},
  keywords = {cloud,containers,dockers,virtual machines},
  number = {3},
  pages = {81--84},
  publisher = {Published by the IEEE Computer Society},
  title = {{Containers and cloud: From LXC to docker to kubernetes}},
  volume = {1},
  year = {2014}
}


@inproceedings{Bharadhwaj.2019,
 author = {Bharadhwaj, Homanga and Wang, Zihan and Bengio, Yoshua and Paull, Liam},
 title = {A Data-Efficient Framework for Training and Sim-to-Real Transfer of Navigation Policies},
 publisher = {IEEE},
 booktitle = {2019 International Conference on Robotics and Automation (ICRA)},
 year = {2019},
 doi = {10.1109/icra.2019.8794310}
}


@Manual{biblatex:manual,
  Title                    = {The Biblatex Package},
  Author                   = {Philipp Lehman},
  Year                     = {2014},
  Edition                  = {Version 2.9a},
  Organization             = {CTAN.org},
  Url                      = {http://ctan.org/pkg/biblatex},

  Bdsk-url-1               = {http://ctan.org/pkg/biblatex},
  Owner                    = {tobiasstraub},
  Timestamp                = {2015.01.09}
}


@Thesis{Boettger:Diplomarbeit,
  Title                    = {Cloud Computing richtig gemacht: Ein Vorgehensmodell zur Auswahl von SaaS-Anwendungen: Am Beispiel eines hybriden Cloud-Ansatzes für Vertriebssoftware in KMU},
  Author                   = {Böttger, Markus},
  Institution              = {Universität Stuttgart},
  Type                     = {Diplomarbeit},
  Year                     = {2012},

  Edition                  = {1. Auflage},
  ISBN                     = {978-384-28281-7-9},
  Keywords                 = {Cloud computing. Hybrider Betrieb. On-Premise Software},
  Publisher                = {Diplomica Verlag GmbH}
}


@Book{BuschlingerStaab,
  Title                    = {{UNIX} für Software-Entwickler - Konzepte, Werkzeuge und Ideen},
  Author                   = {Frank Staab},
  Year                     = {1993},
  ISBN                     = {978-3-519-02290-9},
  Publisher                = {Teubner},

  Bibsource                = {dblp computer science bibliography, http://dblp.org},
  Biburl                   = {http://dblp.uni-trier.de/rec/bib/books/daglib/0069663}
}


@Article{Carvalho:PJ:2012-1,
  Title                    = {Documenting ITIL processes with LaTeX (Portuguese)},
  Author                   = {Rayans Carvalho and Francisco Reinaldo},
  Year                     = {2012},
  Number                   = {1},
  Url                      = {http://tug.org/pracjourn/2012-1/rayans},

  Bdsk-url-1               = {http://tug.org/pracjourn/2012-1/rayans},
  Journal                  = {The Prac\TeX\ Journal}
}


@article{COLLINS2022101217,
  title = {Power TAC: Software architecture for a competitive simulation of sustainable smart energy markets},
  journal = {SoftwareX},
  volume = {20},
  pages = {101217},
  year = {2022},
  issn = {2352-7110},
  doi = {https://doi.org/10.1016/j.softx.2022.101217},
  url = {https://www.sciencedirect.com/science/article/pii/S2352711022001352},
  author = {John Collins and Wolfgang Ketter},
  keywords = {Competitive benchmarking, Simulation, Open-source software, Sustainable electricity, Smart markets, Trading agents},
  abstract = {Power TAC (www.powertac.org) is a discrete-time competitive simulation that models a retail electricity market. Since 2012 it has been the foundation of an annual competition, challenging teams from around the world to build autonomous trading agents that communicate with the simulation over the internet. These “retail brokers” offer energy services to customers through tariff contracts, and must then serve those customers by trading in a wholesale market. Hourly differences between wholesale market positions and net consumption by their subscribed customers must be cleared in a local balancing market using a combination of demand response and wholesale balancing energy. The simulation server is open source and highly modular, designed to be accessible to inexperienced student developers. It makes heavy use of annotations and aspect-oriented programming to achieve consistency and ensure that all important events are recorded, allowing simulations to be re-played and analyzed in depth.}
}


@inproceedings{Cutler.2014,
 author = {Cutler, Mark and Walsh, Thomas J. and How, Jonathan P.},
 title = {Reinforcement learning with multi-fidelity simulators},
 publisher = {IEEE},
 booktitle = {2014 IEEE International Conference on Robotics and Automation (ICRA)},
 year = {2014},
 doi = {10.1109/icra.2014.6907423}
}


@article{DBLP:journals/corr/abs-1910-10537,
  author    = {Reda Bahi Slaoui and
               William R. Clements and
               Jakob N. Foerster and
               S{\'{e}}bastien Toth},
  title     = {Robust Domain Randomization for Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1910.10537},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.10537},
  eprinttype = {arXiv},
  eprint    = {1910.10537},
  timestamp = {Fri, 25 Oct 2019 14:59:26 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-10537.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@misc{Endres,
  author = {Endres, Cornelia},
  booktitle = {Bachelor Print},
  title = {{Das Experteninterview – Leitfaden f{\"{u}}r die Bachelorarbeit}},
  urldate = {2019-08-09}
}


@article{FabioMuratore.2018,
 abstract = {Domain Randomization for Simulation-Based Policy Optimization with Transferability AssessmentFabio Muratore,~Felix Treede,~Michael Gienger,~Ja...},
 author = {{Fabio Muratore} and {Felix Treede} and {Michael Gienger} and {Jan Peters}},
 year = {2018},
 title = {Domain Randomization for Simulation-Based Policy Optimization with Transferability Assessment},
 url = {http://proceedings.mlr.press/v87/muratore18a},
 pages = {700--713},
 issn = {2640-3498},
 journal = {Conference on Robot Learning},
 file = {Domain Randomization for Simulation-Based Policy Optimiz:Attachments/Domain Randomization for Simulation-Based Policy Optimiz.pdf:application/pdf}
}


@incollection{Farahani.2021,
 abstract = {Classical machine learning assumes that the training and test sets come from the same distributions. Therefore, a model learned from the labeled training data is expected to perform well on the test data. However, this assumption may not always hold in real-world...},
 author = {Farahani, Abolfazl and Voghoei, Sahar and Rasheed, Khaled and Arabnia, Hamid R.},
 title = {A Brief Review of Domain Adaptation},
 url = {https://link.springer.com/chapter/10.1007/978-3-030-71704-9_65#chapter-info},
 pages = {877--894},
 publisher = {{Springer, Cham}},
 booktitle = {Advances in Data Science and Information Engineering},
 year = {2021},
 doi = {10.1007/978-3-030-71704-9{\textunderscore }65}
}

@Phdthesis{GuttenPlag,
  Title                    = {Verfassung und Verfassungsvertrag : konstitutionelle Entwicklungsstufen in den USA und der EU},
  Author                   = {Karl-Theodor {zu Guttenberg}},
  Institution              = {Universität Bayreuth},
  Year                     = {2009},
  Note                     = {Doktorgrad am 23.2.2011 aberkannt},
  Type                     = {Dissertation},

  Owner                    = {tobiasstraub},
  Timestamp                = {2015.01.09}
}

@inproceedings{Hentati.2018,
 author = {Hentati, Aicha Idriss and Krichen, Lobna and Fourati, Mohamed and Fourati, Lamia Chaari},
 title = {Simulation Tools, Environments and Frameworks for UAV Systems Performance Analysis},
 publisher = {IEEE},
 booktitle = {2018 14th International Wireless Communications {\&} Mobile Computing Conference (IWCMC)},
 year = {2018},
 doi = {10.1109/iwcmc.2018.8450505},
 file = {Simulation_Tools_Environments_and_Frameworks_for_UAV_Systems_Performance_Analysis:Attachments/Simulation_Tools_Environments_and_Frameworks_for_UAV_Systems_Performance_Analysis.pdf:application/pdf}
}

@Article{hitzler2011optimierung,
  Title                    = {Optimierung und Intensivierung des Einsatzes von Planspielen an Hochschulen},
  Author                   = {Trautwein, Friedrich},
  Year                     = {2011},
  Pages                    = {101--125},

  Comment                  = {weitere Autoren: Hitzler, Sebastian and Z{\"u}rn, Birgit and},
  Journal                  = {Planspiele--Qualit{\"a}t und Innovation: Neue Ans{\"a}tze aus Theorie und Praxis, hrsg. von: Hitzler, S}
}


@book{Indrasiri2018,
  abstract = {Includes index. "Microservices for the Enterprise covers state-of-the-art techniques around microservices messaging, service development and description, service discovery, governance, and data management technologies and guides you through the microservices design process. Also included is the importance of organizing services as core versus atomic, composite versus integration, and API versus edge, and how such organization helps to eliminate the use of a central ESB and expose services through an API gateway"-- The case for microservices -- Designing microservices -- Inter-service communication -- Developing services -- Data management -- Microservices governance -- Integrating microservices -- Deploying and running microservices -- Service mesh -- APIs, events, and streams -- Microservices security fundamentals -- Securing microservices -- Observability.},
  author = {Indrasiri, Kasun and Siriwardena, Prabath},
  booktitle = {Microservices for the Enterprise},
  doi = {10.1007/978-1-4842-3858-5},
  isbn = {9781484238578},
  title = {{Microservices for the Enterprise}},
  year = {2018}
}


@Book{keinAutorAberHerausgeber,
  Title                    = {Buch ohne Autor, aber mit Herausgeber},
  Year                     = {2020},
  Editor                   = {Max Meier},
  Location                 = {Bielefeld},
  Publisher                = {Nonsens-Verlag}
}


@misc{Korber.2021,
 abstract = {This letter compares the performance of four different, popular simulation environments for robotics and reinforcement learning (RL) through a series of benchmarks. The benchmarked scenarios are designed carefully with current industrial applications in mind. Given the need to run simulations as fast as possible to reduce the real-world training time of the RL agents, the comparison includes not only different simulation environments but also different hardware configurations, ranging from an entry-level notebook up to a dual CPU high performance server. We show that the chosen simulation environments benefit the most from single core performance. Yet, using a multi core system, multiple simulations could be run in parallel to increase the performance.},
 author = {K{\"o}rber, Marian and Lange, Johann and Rediske, Stephan and Steinmann, Simon and Gl{\"u}ck, Roland},
 date = {2021},
 title = {Comparing Popular Simulation Environments in the Scope of Robotics and Reinforcement Learning},
 url = {https://arxiv.org/pdf/2103.04616},
 keywords = {Artificial Intelligence (cs.AI);Machine Learning (cs.LG);Robotics (cs.RO)},
 file = {Comparing Popular Simulation Environments in the Scope o:Attachments/Comparing Popular Simulation Environments in the Scope o.pdf:application/pdf}
}


@Online{langeURL,
  Title                    = {Lange URL als Herausforderung für den Zeilenumbruch},
  Author                   = {Google},
  Url                      = {http://www.google.de/search?q=biblatex+umbruch+url&hl=de&gbv=2&oq=biblatex+umbruch+url&gs_l=heirloom-serp.12...0.0.0.6831.0.0.0.0.0.0.0.0..0.0.msedr...0...1ac..34.heirloom-serp..0.0.0.5959BWSvzu0},
  Year                     = {o.J.}
}



% --------------------------------------------------------------------------------------

@Inbook{Mann,
  Title                    = {Beyond Systematic Innovation},
  Author                   = {Mann, D.},
  Editor                   = {Jöstingmeier, B. and Boeddrich, H.-J.},
  Pages                    = {45--61},
  Publisher                = {DUV},
  Year                     = {2005},

  Address                  = {Wiesbaden},

  Booktitle                = {Cross-Cultural Innovation},
  Owner                    = {tobiasstraub},
  Timestamp                = {2015.01.04}
}

@Report{mayer:PA1,
  Title                    = {Automatisierung von Zellformatierungen in Excel},
  Author                   = {Lieschen Mayer},
  Institution              = {DHBW Stuttgart},
  Type                     = {1. Projektarbeit},
  Year                     = {2015},
  Subtitle                 = {Entwicklung eines Prototypen mit VBA},

  Owner                    = {tobiasstraub},
  Timestamp                = {2015.01.28}
}

@Report{mayerLukas:PA1,
  Title                    = {Unternehmenskommunikation mittels RFC822},
  Author                   = {Lukas Mayer},
  Institution              = {DHBW Stuttgart},
  Type                     = {1. Projektarbeit},
  Year                     = {2015}
}

@book{Mayring2002,
  abstract = {Qualitative Forschung ist keine beliebig einsetzbare Technik, sondern eine Grundhaltung, ein Denkstil, der immer streng am Gegenstand orientiert ist. Das Buch stellt Bez{\"{u}}ge zum Gegenstandsfeld her und m{\"{o}}chte einer Trennung zwischen Gegenstandsspezialisten und Methodenspezialisten entgegenwirken. Es bietet Unterst{\"{u}}tzung bei der {\"{U}}berpr{\"{u}}fung der Aussagekraft von Projekten und deren Methodik.},
  address = {Weinheim, Basel},
  author = {Mayring, Philipp},
  edition = {6. Auflage},
  isbn = {978-3-407-29093-9},
  pages = {170},
  publisher = {Beltz},
  title = {{Einf{\"{u}}hrung in die qualitative Sozialforschung}},
  year = {2002}
}

@techreport{Mell2011,
  abstract = {The National Institute of Standards and Technology (NIST) developed this document in furtherance of its statutory responsibilities under the Federal Information Security Management Act (FISMA) of 2002, Public Law 107-347. NIST is responsible for developing standards and guidelines, including minimum requirements, for providing adequate information security for all agency operations and assets; but such standards and guidelines shall not apply to national security systems. This guideline is consistent with the requirements of the Office of Management and Budget (OMB) Circular A-130, Section 8b(3), Securing Agency Information Systems, as analyzed in A-130, Appendix IV: Analysis of Key Sections. Supplemental information is provided in A-130, Appendix III. This guideline has been prepared for use by Federal agencies. It may be used by nongovernmental organizations on a voluntary basis and is not subject to copyright, though attribution is desired. Nothing in this document should be taken to contradict standards and guidelines made mandatory and binding on Federal agencies by the Secretary of Commerce under statutory authority, nor should these guidelines be interpreted as altering or superseding the existing authorities of the Secretary of Commerce, Director of the OMB, or any other Federal official.},
  author = {Mell, Peter and Grance, Timothy},
  booktitle = {National Institute of Standard and Technology},
  publisher = {U.S. Department of Commerce},
  title = {{The NIST Definition of Cloud Computing - Special Publication 800-145}},
  url = {http://faculty.winthrop.edu/domanm/csci411/Handouts/NIST.pdf},
  year = {2011}
}

@Book{MitDreiAutoren,
  Title                    = {Test},
  Author                   = {Max Muller and Mayer, Laura and Schulze, Werner},
  Year                     = {2013},

  Owner                    = {tobiasstraub},
  Timestamp                = {2015.01.04}
}

@Book{MitZweiAutoren,
  Title                    = {Test},
  Author                   = {Max Müller and Mayer, Lieschen},
  Year                     = {2013}
}

@article{Muratore.2021,
 author = {Muratore, Fabio and Eilers, Christian and Gienger, Michael and Peters, Jan},
 year = {2021},
 title = {Data-Efficient Domain Randomization With Bayesian Optimization},
 pages = {911--918},
 volume = {6},
 number = {2},
 journal = {IEEE Robotics and Automation Letters},
 doi = {10.1109/LRA.2021.3052391},
 file = {Data-Efficient Domain Randomization With Bayesian Optimi:Attachments/Data-Efficient Domain Randomization With Bayesian Optimi.pdf:application/pdf}
}

@article{Nguyen.2020,
 author = {Nguyen, Thanh Thi and Nguyen, Ngoc Duy and Vamplew, Peter and Nahavandi, Saeid and Dazeley, Richard and Lim, Chee Peng},
 year = {2020},
 title = {A multi-objective deep reinforcement learning framework},
 pages = {103915},
 volume = {96},
 issn = {09521976},
 journal = {Engineering Applications of Artificial Intelligence},
 doi = {10.1016/j.engappai.2020.103915},
 file = {A multi-objective deep reinforcement learning framework:Attachments/A multi-objective deep reinforcement learning framework.pdf:application/pdf}
}

@Book{OhneAutoren,
  Title                    = {UnbekannterAutor},
  Author                   = {o.V.},
  Year                     = {2016}
}

@Book{OhneAutorenOhneJahr,
  Title                    = {UnbekannterAutor, unbekannterTitel},
  Author                   = {o.V.},

  Owner                    = {tobiasstraub},
  Timestamp                = {2015.01.04}
}

@Book{OhneAutorenOhneJahr2,
  Title                    = {UnbekannterAutor, unbekannterTitel die Zweite},
  Author                   = {o.V.},

  Owner                    = {tobiasstraub},
  Timestamp                = {2015.01.04}
}

@misc{Panerati.332021,
 abstract = {Robotic simulators are crucial for academic research and education as well as the development of safety-critical applications. Reinforcement learning environments -- simple simulations coupled with a problem specification in the form of a reward function -- are also important to standardize the development (and benchmarking) of learning algorithms. Yet, full-scale simulators typically lack portability and parallelizability. Vice versa, many reinforcement learning environments trade-off realism for high sample throughputs in toy-like problems. While public data sets have greatly benefited deep learning and computer vision, we still lack the software tools to simultaneously develop -- and fairly compare -- control theory and reinforcement learning approaches. In this paper, we propose an open-source OpenAI Gym-like environment for multiple quadcopters based on the Bullet physics engine. Its multi-agent and vision based reinforcement learning interfaces, as well as the support of realistic collisions and aerodynamic effects, make it, to the best of our knowledge, a first of its kind. We demonstrate its use through several examples, either for control (trajectory tracking with PID control, multi-robot flight with downwash, etc.) or reinforcement learning (single and multi-agent stabilization tasks), hoping to inspire future research that combines control theory and machine learning.},
 author = {Panerati, Jacopo and Zheng, Hehui and Zhou, SiQi and Xu, James and Prorok, Amanda and Schoellig, Angela P.},
 date = {3/3/2021},
 title = {Learning to Fly -- a Gym Environment with PyBullet Physics for  Reinforcement Learning of Multi-agent Quadcopter Control},
 url = {https://arxiv.org/pdf/2103.02142},
 keywords = {Computer Science - Learning;Computer Science - Robotics;Machine Learning (cs.LG);Robotics (cs.RO)},
 file = {Learning to Fly -- a Gym Environment with PyBullet Physi:Attachments/Learning to Fly -- a Gym Environment with PyBullet Physi.pdf:application/pdf}
}

@Book{Preiss,
  Title                    = {Entwurf und Verarbeitung relationaler Datenbanken},
  Author                   = {Preiß, N.},
  Year                     = {2007},
  Publisher                = {Oldenbourg},

  Address                  = {München/Wien},
  Owner                    = {tobiasstraub},
  Timestamp                = {2015.01.04}
}

@Article{Primaerquelle,
  author   = {Originalautor},
  title    = {Originalliteratur, die nicht direkt zitiert wird und auch nicht im Verzeichnis erscheinen soll},
  year     = {2000},
  journal = {Journal of Fake Sciences},
  keywords = {ausblenden},
}

@inproceedings{Reda.2020,
 author = {Reda, Daniele and Tao, Tianxin and {van de Panne}, Michiel},
 title = {Learning to Locomote: Understanding How Environment Design Matters for Deep Reinforcement Learning},
 pages = {1--10},
 publisher = {ACM},
 editor = {Reda, Daniele and Tao, Tianxin and {van de Panne}, Michiel},
 booktitle = {Motion, Interaction and Games},
 year = {2020},
 address = {New York, NY, USA},
 doi = {10.1145/3424636.3426907}
}

@proceedings{Reda.2020b,
 year = {2020},
 title = {Motion, Interaction and Games},
 address = {New York, NY, USA},
 publisher = {ACM},
 editor = {Reda, Daniele and Tao, Tianxin and {van de Panne}, Michiel},
 file = {Learning to Locomote Understanding How Environment Desig:Attachments/Learning to Locomote Understanding How Environment Desig.pdf:application/pdf}
}

@Online{SAP:HANA,
  Title                    = {Real-time Analysis of Complaints for Life Sciences},
  Author                   = {{SAP AG}},
  Url                      = {http://hana.sap.com/abouthana/why-hana/usecases/real-time-analysis-complaints-life-sciences.html},
  Year                     = {o.J.},

  Urldate                  = {2015-01-05},

  Date-modified            = {2015-01-14 22:18:32 +0100},
  Owner                    = {tobiasstraub},
  Timestamp                = {2015.01.05}
}

@Book{Schlosser,
  Title                    = {Wissenschaftliche Arbeiten schreiben mit LATEX: Leitfaden für Einsteiger},
  Author                   = {Schlosser, Joachim},
  Year                     = {2014},
  Edition                  = {5., überarb. Aufl.},
  ISBN                     = {978-3-8266-9486-8},
  Publisher                = {mitp-Verlag},

  Bdsk-url-1               = {http://deposit.d-nb.de/cgi-bin/dokserv?id=4527943&prov=M&dok_var=1&dok_ext=htm}
}

@inproceedings{Schuderer.2021,
 abstract = {Reinforcement learning (RL) is being used to create self-adaptive agents, where RL researchers commonly create and employ simulations of the problem domains to train and evaluate various RL algorithms and their variants. This activity is in need of methodological and...},
 author = {Schuderer, Andreas and Bromuri, Stefano and {van Eekelen}, Marko},
 title = {Sim-Env: Decoupling OpenAI Gym Environments from Simulation Models},
 url = {https://link.springer.com/chapter/10.1007/978-3-030-85739-4_39},
 pages = {390--393},
 publisher = {{Springer, Cham}},
 booktitle = {International Conference on Practical Applications of Agents and Multi-Agent Systems},
 year = {2021},
 doi = {10.1007/978-3-030-85739-4{\textunderscore }39}
}

@Book{Sekundaerquelle,
  author = {Sekundärautor},
  title  = {Sekundärliteratur wird tatsächlich ins Verzeichnis aufgenommen},
  year   = {2018},
}

@Book{Staab,
  Title                    = {Logik und Algebra: eine praxisbezogene Einführung für Informatiker und Wirtschaftsinformatiker},
  Author                   = {Staab, Frank},
  Year                     = {2012},
  Edition                  = {2., überarb. Aufl.},
  ISBN                     = {978-3-486-71697-9},
  Pages                    = {148},
  Publisher                = {Oldenbourg},

  Address                  = {München}
}

@Article{Stoi,
  Title                    = {Management und Controlling von Intangibles},
  Author                   = {Stoi, R.},
  Year                     = {2003},
  Number                   = {1},
  Pages                    = {34--46},
  Volume                   = {4},

  Journal                  = {Studium \& Praxis},
  Owner                    = {tobiasstraub},
  Timestamp                = {2015.01.04}
}

@book{Sutton.2018,
 abstract = {{\textless}b{\textgreater}The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence.{\textless}/b{\textgreater}
  Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In {\textless}i{\textgreater}Reinforcement Learning{\textless}/i{\textgreater}, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics.{\textless}/p{\textgreater}
  Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.{\textless}/p{\textgreater}},
 author = {Sutton, Richard S. and Barto, Andrew G.},
 year = {2018},
 title = {Reinforcement Learning, second edition: An Introduction},
 publisher = {{MIT Press}},
 isbn = {9780262352703}
}

@Inproceedings{Trautwein:Erfolgsfaktoren,
  Title                    = {Erfolgsfaktoren beim internationalen Planspieleinsatz},
  Author                   = {Friedrich Trautwein and Christina Trautwein},
  Booktitle                = {17. TOPSIM-Anwendertreffen},
  Editor                   = {{Tata Interactive Systems GmbH}},
  Year                     = {2008},

  Owner                    = {tobiasstraub},
  Timestamp                = {2015.01.04}
}

@Inbook{Trautwein:Nokia,
  Title                    = {Nokia kämpft um die Vorherrschaft: Analyse der Mobiltelefonbranche},
  Author                   = {Friedrich Trautwein and Christina Trautwein},
  Editor                   = {R. Dillerup and R. Stoi},
  Pages                    = {81-84},
  Publisher                = {Vahlen Verlag},
  Year                     = {2008},

  Address                  = {München},

  Booktitle                = {Praxis der Unternehmensführung},
  Owner                    = {tobiasstraub},
  Timestamp                = {2015.01.04}
}

@Article{trautwein2004berufliche,
  Title                    = {Berufliche Handlungskompetenz als Studienziel},
  Author                   = {Trautwein, Friedrich},
  Year                     = {2004},

  Journal                  = {Hohenheim: Verlag Wissenschaft und Praxis}
}

@Article{trautwein2011unternehmensplanspiele,
  Title                    = {Unternehmensplanspiele im industriebetrieblichen Hochschulstudium},
  Author                   = {Trautwein, Christina},
  Year                     = {2011},
  Volume                   = {147},

  Journal                  = {Analyse von Kompetenzerwerb, Motivation und Zufriedenheit am Beispiel des Unternehmensplanspiels TOPSIM--General Management II. Wiesbaden: Gabler}
}

@Misc{Umlauttest,
  Title                    = {Umlaute: Äöüß},

  Author                   = {äöüß€},
  HowPublished             = {nur ein Test},

  Date-modified            = {2015-01-14 22:02:12 +0100}
}

@misc{Vuong.2019,
 abstract = {Recently, reinforcement learning (RL) algorithms have demonstrated remarkable success in learning complicated behaviors from minimally processed input. However, most of this success is limited to simulation. While there are promising successes in applying RL algorithms directly on real systems, their performance on more complex systems remains bottle-necked by the relative data inefficiency of RL algorithms. Domain randomization is a promising direction of research that has demonstrated impressive results using RL algorithms to control real robots. At a high level, domain randomization works by training a policy on a distribution of environmental conditions in simulation. If the environments are diverse enough, then the policy trained on this distribution will plausibly generalize to the real world. A human-specified design choice in domain randomization is the form and parameters of the distribution of simulated environments. It is unclear how to the best pick the form and parameters of this distribution and prior work uses hand-tuned distributions. This extended abstract demonstrates that the choice of the distribution plays a major role in the performance of the trained policies in the real world and that the parameter of this distribution can be optimized to maximize the performance of the trained policies in the real world},
 author = {Vuong, Quan and Vikram, Sharad and Su, Hao and Gao, Sicun and Christensen, Henrik I.},
 date = {2019},
 title = {How to pick the domain randomization parameters for sim-to-real transfer of reinforcement learning policies?},
 url = {https://arxiv.org/pdf/1903.11774},
 keywords = {Artificial Intelligence (cs.AI);Machine Learning (cs.LG);Machine Learning (stat.ML)},
 file = {How to pick the domain randomization parameters for sim-:Attachments/How to pick the domain randomization parameters for sim-.pdf:application/pdf}
}

@misc{W3SchoolUnderscore,
    author = {W3},
    keywords = {html,w3},
    pages = {1},
    title = {{HTML Semantic Elements}},
    url = {https://www.w3schools.com/html/html5{\_}semantic{\_}elements.asp},
    urldate = {2020-11-28},
    year = {2020}
}

@Online{wiki:Wirtschaftsinformatik,
  Title                    = {Wirtschaftsinformatik --- Wikipedia{,} Die freie Enzyklopädie},
  Author                   = {Wikipedia},
  Url                      = {http://de.wikipedia.org/w/index.php?title=Wirtschaftsinformatik&oldid=130413078},
  Year                     = {o.J.},

  Urldate                  = {2014-05-14},

  Bdsk-url-1               = {http://de.wikipedia.org/w/index.php?title=Wirtschaftsinformatik&oldid=130413078}
}

@Manual{Win8,
  Title                    = {Produkthandbuch für Windows 8 und Windows RT},
  Author                   = {Microsoft},
  Year                     = {2012},
  Edition                  = {Version 1.0},

  Bdsk-url-1               = {https://www.microsoft.com/de-de/download/details.aspx?id=35406},
  Owner                    = {tobiasstraub},
  Timestamp                = {2015.01.05}
}
@Inbook{Wind,
  Title                    = {Cloud Management mit Open-Source-Plattformen},
  Author                   = {Stefan Wind},
  Editor                   = {Susanne Strahringer},
  Publisher                = {dpunkt.verlag GmbH},
  Year                     = {2012},

  Booktitle                = {Open Source - Konzepte, Risiken, Trends}
}
@misc{Yuxi.2019,
  doi = {10.48550/ARXIV.1908.06973},
  url = {https://arxiv.org/abs/1908.06973},
  author = {Li, Yuxi},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Reinforcement Learning Applications},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@incollection{Zhao.,
 author = {Zhao, Wenshuai and Queralta, Jorge Pena and Westerlund, Tomi},
 title = {Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey},
 pages = {737--744},
 doi = {10.1109/SSCI47803.2020.9308468},
 file = {Sim-to-Real Transfer in Deep Reinforcement Learning for:Attachments/Sim-to-Real Transfer in Deep Reinforcement Learning for.pdf:application/pdf}
}
@inproceedings{Zhao.2020,
 author = {Zhao, Wenshuai and Queralta, Jorge Pena and Westerlund, Tomi},
 title = {Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey},
 publisher = {IEEE},
 booktitle = {2020 IEEE Symposium Series on Computational Intelligence (SSCI)},
 year = {2020},
 doi = {10.1109/ssci47803.2020.9308468}
}

@misc{Zhao.6272019,
 abstract = {With the recent advances in Reinforcement Learning (RL), there have been tremendous interests in employing RL for recommender systems. However, directly training and evaluating a new RL-based recommendation algorithm needs to collect users' real-time feedback in the real system, which is time and efforts consuming and could negatively impact on users' experiences. Thus, it calls for a user simulator that can mimic real users' behaviors where we can pre-train and evaluate new recommendation algorithms. Simulating users' behaviors in a dynamic system faces immense challenges -- (i) the underlining item distribution is complex, and (ii) historical logs for each user are limited. In this paper, we develop a user simulator base on Generative Adversarial Network (GAN). To be specific, the generator captures the underlining distribution of users' historical logs and generates realistic logs that can be considered as augmentations of real logs; while the discriminator not only distinguishes real and fake logs but also predicts users' behaviors. The experimental results based on real-world e-commerce data demonstrate the effectiveness of the proposed simulator.},
 author = {Zhao, Xiangyu and Xia, Long and Zou, Lixin and Yin, Dawei and Tang, Jiliang},
 date = {6/27/2019},
 title = {Toward Simulating Environments in Reinforcement Learning Based  Recommendations},
 url = {https://arxiv.org/pdf/1906.11462},
 keywords = {Computer Science - Information Retrieval;Computer Science - Learning;Information Retrieval (cs.IR);Machine Learning (cs.LG)},
 file = {Toward Simulating Environments in Reinforcement Learning:Attachments/Toward Simulating Environments in Reinforcement Learning.pdf:application/pdf}
}

@inproceedings{Zubow.2021,
 author = {Zubow, Anatolij and R{\"o}sler, Sascha and Gaw{\l}owicz, Piotr and Dressler, Falko},
 title = {GrGym},
 publisher = {ACM},
 booktitle = {Proceedings of the 22nd International Workshop on Mobile Computing Systems and Applications},
 year = {2021},
 address = {New York, NY, USA},
 doi = {10.1145/3446382.3448358}
}

@Comment{jabref-meta: databaseType:biblatex;}
